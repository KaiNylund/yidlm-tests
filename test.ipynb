{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from datasets import load_from_disk\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(os.listdir(\"./lang_splits/\")) - set(os.listdir(\"./lang_models/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21] [22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21] [44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21] [65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85]\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43] [22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43]\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43] [44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]\n",
      "[22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43] [65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85]\n",
      "[44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "[44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] [22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43]\n",
      "[44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] [44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]\n",
      "[44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] [65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85]\n",
      "[65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "[65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85] [22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43]\n",
      "[65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85] [44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]\n",
      "[65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85] [65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85]\n"
     ]
    }
   ],
   "source": [
    "batch_idxs = np.array_split(np.array(list(range(86))), 4)\n",
    "\n",
    "for b1_idxs in batch_idxs:\n",
    "    for b2_idxs in batch_idxs:\n",
    "        print(b1_idxs, b2_idxs)\n",
    "\n",
    "#print(np.meshgrid([1, 2, 3, 8], [3, 2, 9, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_mt5 = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250112\n",
      "['shared.weight',\n",
      " 'encoder.embed_tokens.weight',\n",
      " 'encoder.block.0.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.0.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.0.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.0.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
      " 'encoder.block.0.layer.0.layer_norm.weight',\n",
      " 'encoder.block.0.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.0.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.0.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.0.layer.1.layer_norm.weight',\n",
      " 'encoder.block.1.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.1.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.1.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.1.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.1.layer.0.layer_norm.weight',\n",
      " 'encoder.block.1.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.1.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.1.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.1.layer.1.layer_norm.weight',\n",
      " 'encoder.block.2.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.2.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.2.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.2.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.2.layer.0.layer_norm.weight',\n",
      " 'encoder.block.2.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.2.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.2.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.2.layer.1.layer_norm.weight',\n",
      " 'encoder.block.3.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.3.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.3.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.3.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.3.layer.0.layer_norm.weight',\n",
      " 'encoder.block.3.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.3.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.3.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.3.layer.1.layer_norm.weight',\n",
      " 'encoder.block.4.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.4.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.4.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.4.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.4.layer.0.layer_norm.weight',\n",
      " 'encoder.block.4.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.4.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.4.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.4.layer.1.layer_norm.weight',\n",
      " 'encoder.block.5.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.5.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.5.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.5.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.5.layer.0.layer_norm.weight',\n",
      " 'encoder.block.5.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.5.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.5.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.5.layer.1.layer_norm.weight',\n",
      " 'encoder.block.6.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.6.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.6.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.6.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.6.layer.0.layer_norm.weight',\n",
      " 'encoder.block.6.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.6.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.6.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.6.layer.1.layer_norm.weight',\n",
      " 'encoder.block.7.layer.0.SelfAttention.q.weight',\n",
      " 'encoder.block.7.layer.0.SelfAttention.k.weight',\n",
      " 'encoder.block.7.layer.0.SelfAttention.v.weight',\n",
      " 'encoder.block.7.layer.0.SelfAttention.o.weight',\n",
      " 'encoder.block.7.layer.0.layer_norm.weight',\n",
      " 'encoder.block.7.layer.1.DenseReluDense.wi_0.weight',\n",
      " 'encoder.block.7.layer.1.DenseReluDense.wi_1.weight',\n",
      " 'encoder.block.7.layer.1.DenseReluDense.wo.weight',\n",
      " 'encoder.block.7.layer.1.layer_norm.weight',\n",
      " 'encoder.final_layer_norm.weight',\n",
      " 'decoder.embed_tokens.weight',\n",
      " 'decoder.block.0.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.0.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.0.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.0.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
      " 'decoder.block.0.layer.0.layer_norm.weight',\n",
      " 'decoder.block.0.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.0.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.0.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.0.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.0.layer.1.layer_norm.weight',\n",
      " 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.0.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.0.layer.2.layer_norm.weight',\n",
      " 'decoder.block.1.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.1.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.1.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.1.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.1.layer.0.layer_norm.weight',\n",
      " 'decoder.block.1.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.1.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.1.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.1.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.1.layer.1.layer_norm.weight',\n",
      " 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.1.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.1.layer.2.layer_norm.weight',\n",
      " 'decoder.block.2.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.2.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.2.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.2.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.2.layer.0.layer_norm.weight',\n",
      " 'decoder.block.2.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.2.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.2.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.2.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.2.layer.1.layer_norm.weight',\n",
      " 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.2.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.2.layer.2.layer_norm.weight',\n",
      " 'decoder.block.3.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.3.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.3.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.3.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.3.layer.0.layer_norm.weight',\n",
      " 'decoder.block.3.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.3.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.3.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.3.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.3.layer.1.layer_norm.weight',\n",
      " 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.3.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.3.layer.2.layer_norm.weight',\n",
      " 'decoder.block.4.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.4.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.4.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.4.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.4.layer.0.layer_norm.weight',\n",
      " 'decoder.block.4.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.4.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.4.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.4.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.4.layer.1.layer_norm.weight',\n",
      " 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.4.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.4.layer.2.layer_norm.weight',\n",
      " 'decoder.block.5.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.5.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.5.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.5.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.5.layer.0.layer_norm.weight',\n",
      " 'decoder.block.5.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.5.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.5.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.5.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.5.layer.1.layer_norm.weight',\n",
      " 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.5.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.5.layer.2.layer_norm.weight',\n",
      " 'decoder.block.6.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.6.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.6.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.6.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.6.layer.0.layer_norm.weight',\n",
      " 'decoder.block.6.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.6.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.6.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.6.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.6.layer.1.layer_norm.weight',\n",
      " 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.6.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.6.layer.2.layer_norm.weight',\n",
      " 'decoder.block.7.layer.0.SelfAttention.q.weight',\n",
      " 'decoder.block.7.layer.0.SelfAttention.k.weight',\n",
      " 'decoder.block.7.layer.0.SelfAttention.v.weight',\n",
      " 'decoder.block.7.layer.0.SelfAttention.o.weight',\n",
      " 'decoder.block.7.layer.0.layer_norm.weight',\n",
      " 'decoder.block.7.layer.1.EncDecAttention.q.weight',\n",
      " 'decoder.block.7.layer.1.EncDecAttention.k.weight',\n",
      " 'decoder.block.7.layer.1.EncDecAttention.v.weight',\n",
      " 'decoder.block.7.layer.1.EncDecAttention.o.weight',\n",
      " 'decoder.block.7.layer.1.layer_norm.weight',\n",
      " 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight',\n",
      " 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight',\n",
      " 'decoder.block.7.layer.2.DenseReluDense.wo.weight',\n",
      " 'decoder.block.7.layer.2.layer_norm.weight',\n",
      " 'decoder.final_layer_norm.weight',\n",
      " 'lm_head.weight']\n"
     ]
    }
   ],
   "source": [
    "pprint(pretrained_mt5.state_dict()[\"shared.weight\"].size()[0])\n",
    "\n",
    "pprint(list(pretrained_mt5.state_dict().keys()))\n",
    "# decoder.block.7.layer.2.DenseReluDense.wi_0.weight\n",
    "# decoder.block.7.layer.2.DenseReluDense.wi_1.weight\n",
    "# decoder.block.7.layer.2.DenseReluDense.wo.weight\n",
    "# encoder.block.7.layer.1.DenseReluDense.wi_0.weight\n",
    "# encoder.block.7.layer.1.DenseReluDense.wi_1.weight\n",
    "# encoder.block.7.layer.1.DenseReluDense.wo.weight\n",
    "# decoder.block.7.layer.1.EncDecAttention.q.weight\n",
    "# decoder.block.7.layer.1.EncDecAttention.k.weight\n",
    "# decoder.block.7.layer.1.EncDecAttention.v.weight\n",
    "# decoder.block.7.layer.1.EncDecAttention.o.weight\n",
    "# encoder.block.7.layer.0.SelfAttention.q.weight\n",
    "# encoder.block.7.layer.0.SelfAttention.k.weight\n",
    "# encoder.block.7.layer.0.SelfAttention.v.weight\n",
    "# encoder.block.7.layer.0.SelfAttention.o.weight\n",
    "# shared.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_disk(\"./lang_splits/yi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "דעם מולטיפונקטיאָנאַל געפירט אַרבעט ליכט איז מאָונטעד דורך מאַגנעט מיט וסב רעזולטאַט פֿאַר נויטפאַל מאַכט באַנק. די מאַגנאַץ זענען געבויט אין 2 ענדס פון ליכט צו צוטשעפּען רובֿ פון סערפאַסיז. עס האט אַ דוראַבאַל קאַנסטראַקטאַד אַלומינום גוף און די געפירט ליכט טראגט 450 לומאַנז, פּאַוערד דורך 5200 מאַה קריקאָנלאָדלעך באַטאַרייע (לענג: 223 מם). פּראַוויידינג בוילעט ילומאַניישאַן, עס אויך פֿעיִקייטן 3-דימאַבלע ברייטנאַס לעוועלס צוזאמען מיט סטראָבע און סאָס פאַנגקשאַנז. עס אויך גיט אַ מאָדע פון ​​קאָמאַר אָפּטרייַביק לאָמפּ ווען געוויינט פֿאַר באַקיאַרד, קעמפּינג. עס איז ידעאַל פֿאַר מאַשין ריפּערז, קעמפּינג, באָוטינג אָדער ביי אַ קוקאָוט. און אויך פֿאַר וואַרשטאַט, גאַראַזש, קעלער, קיך אָדער אַרום די הויז און באַקיאַרד\n",
      "אָנפרעגדעטאַל\n",
      "רוף אונז\n",
      "צימער 606, 1סט בילדינג פון באַיטאָנג, ווייכווארג פּאַרק ווו, דזשימעי, קסיאַמען, טשיינאַ\n",
      "טעלעפאָן: 0086-13666087358\n",
      "טעלעפאָן: 0086-15985812061\n",
      "בליצפּאָסט: ywh@loveliking.com\n",
      "אָנפרעג פֿאַר פּרייסליסט\n",
      "פֿאַר ינקוועריז וועגן אונדזער פּראָדוקטן אָדער פּרייסליסט, ביטע לאָזן אונדז דיין E- בריוו און מיר וועלן קאָנטאַקט אונדז אין 24 שעה.\n",
      "אָנפרעג פֿאַר פּרייסליסט\n",
      "לעצטיגע נייעס\n",
      "אויג שוץ שרייַבטיש לאָמפּ\n",
      "11-01-2021\n",
      "אָפט לערנען אונטער אַ סטראָבאָסקאָפּיק ליכט מקור וועט שעדיקן די ...\n",
      "וואָס איז אויג-קאַרינג ליכט?\n",
      "09-07-2021\n",
      "די אַזוי גערופענע אויג שוץ לאָמפּ איז צו מאַכן פּראָסט נידעריק אָפטקייַט ...\n",
      "וואָס טיפּ פון פילטער איז בעסער פֿאַר וואַקוום ...\n",
      "09-07-2021\n",
      "די קראַנט וואַקוום קלינערז האָבן דער הויפּט די פאלגענדע דריי פילטראַץ ...\n",
      "הייס פּראָדוקטן\n",
      "סיטעמאַפּ\n",
      "AMP מאָביל\n",
      "קאָרדלעסס מאַשין וואַקוום קלינער, געפֿירט ליכט מיט מאַגנעטיק באַזע, פלעקסאַבאַל טיש לאַמפּ, Ionvac קאָרדלעסס וואַקוום, טשאַרדזשינג טיש לאַמפּ, געפֿירט אַרבעט ליכט,\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"][\"text\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
